{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Тема проекта\n",
    "-\n",
    "# Какие данные вы взяли для работы, укажите их источник\n",
    "Я взяла набор данных, который предлагает всесторонний обзор лучших аниме 2024 года и полезен для создания систем рекомендаций, визуализации тенденций популярности аниме и их оценок, прогнозирования оценок и популярности.\n",
    "[Источник](https://www.kaggle.com/datasets/bhavyadhingra00020/top-anime-dataset-2024)\n",
    "# Описание каждого признака:\n",
    "1. _Score_ - рейтинг или оценка, присвоенная каждому названию аниме\n",
    "2. _Popularity_ - место в рейтинге каждого аниме по популярности среди зрителей\n",
    "3. _Rank_ - рейтинг каждого названия аниме в наборе данных\n",
    "4. _Members_ - количество участников или зрителей, связанных с каждым аниме.\n",
    "5. _Description_ - краткий обзор сюжета и тем каждого аниме\n",
    "6. _Synonyms_ - альтернативные названия (синонимы), используемые для каждого аниме\n",
    "7. _Japanese_ - оригинальное название аниме на японском языке\n",
    "8. _English_ - переведенное на английский название аниме\n",
    "9. _Type_ - классификация по типу аниме (например, телесериал, фильм, OVA и т.д.)\n",
    "10. _Episodes_ - общее количество серий в каждом аниме-сериале\n",
    "11. _Status_ - текущее состояние аниме (например, продолжается, завершено и т.д.)\n",
    "12. _Aired_ - диапазон дат выхода аниме в эфир\n",
    "13. _Premiered_ - дата первой премьеры аниме\n",
    "14. _Broadcast_ - информация о платформе или канале вещания\n",
    "15. _Producers_ - компании или студии, участвующие в производстве аниме\n",
    "16. _Licensors_ - организации или компании, владеющие лицензионными правами на аниме.\n",
    "17. _Studios_ - анимационные студии, ответственные за производство аниме\n",
    "18. _Source_ - исходный материал для аниме (например, манга, роман, оригинал)\n",
    "19. _Genres_ - категории или жанры, к которым относится аниме\n",
    "20. _Demographic_ - целевая демографическая аудитория аниме (например, SeinenSeinen, ShoujoShoujo, ShounenShounen, JoseiJosei).\n",
    "21. _Duration_ - продолжительность каждого эпизода или фильма\n",
    "22. _Rating_ - возрастной рейтинг контента, присвоенный каждому аниме (например, G, PG, PG-13, R)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "feb355a2577cc191"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Connecting all used libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# A function to create a new column (\"Duration_in_minutes\") based on the columns \"Duration\" and \"Episodes\"\n",
    "def convert_to_minutes(row) -> int:\n",
    "    duration = row['Duration']\n",
    "    number_of_episodes = row['Episodes']\n",
    "    time_parts = duration.split()\n",
    "    if 'hr.' in duration:\n",
    "        hours = int(time_parts[0])\n",
    "        if 'min.' in duration:\n",
    "            minutes = int(time_parts[2])\n",
    "        else:\n",
    "            minutes = 0\n",
    "    else:\n",
    "        hours = 0\n",
    "        minutes = int(time_parts[0])\n",
    "    return int(number_of_episodes * (hours * 60 + minutes))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5ea8aa2d0cfa700",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Preparing of the Pandas output and loading the dataset\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 250)\n",
    "df = pd.read_csv(\"db_anime.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "433d809351e69fea",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDA. Разведочный анализ данных"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a53a1a36fd5f55"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# EDA. 1. How many rows and columns are there in the dataset?\n",
    "rows, columns = df.shape\n",
    "print(f'The dataset has {rows} rows and {columns} columns.')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "201916fdb414902b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# EDA. 2. Find out the data type of each feature\n",
    "data_types = df.dtypes\n",
    "print(\"Data types of each feature:\\n\", data_types)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d652a279107d3a87",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDA. 3. Определите тип данных для каждого объекта с точки зрения анализа\n",
    "- _Непрерывный_: Score, Duration;\n",
    "- _Дискретный_: Popularity, Rank, Members, Episodes;\n",
    "- _Номинальный_: Description, Synonyms, Japanese, English, Type, Status, Aired, Broadcast, Producers, Licensors, Studios, Source, Genres, Demographic;\n",
    "- _Порядковый_: Premiered, Rating;"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef38861be472b6d7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# EDA. 4. Are there gaps in the data?\n",
    "missing_data = df.isnull().sum()\n",
    "print(\"Missing data in each column:\\n\", missing_data)\n",
    "\n",
    "# Handling missing data\n",
    "# For numeric columns, we can fill missing values with the median (because it is numeric columns).\n",
    "numeric_columns = ['Score', 'Popularity', 'Rank', 'Members', 'Episodes']\n",
    "for column in numeric_columns:\n",
    "    if df[column].isnull().sum() != 0:\n",
    "        df[column].fillna(df[column].median(), inplace=True)\n",
    "# For categorical columns, we can fill missing values with the mode.\n",
    "categorical_columns = ['Description', 'Synonyms', 'Japanese', 'English', 'Type', 'Status', 'Aired', 'Premiered',\n",
    "                       'Broadcast', 'Producers', 'Licensors', 'Studios', 'Source', 'Genres', 'Demographic', 'Duration',\n",
    "                       'Rating']\n",
    "for column in categorical_columns:\n",
    "    if df[column].isnull().sum() != 0:\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "\n",
    "# Verify missing data handling\n",
    "missing_data_after = df.isnull().sum()\n",
    "print(\"Missing data after handling:\\n\", missing_data_after)\n",
    "\n",
    "# Creating of new feature \"Duration_in_minutes\"\n",
    "df['Duration_in_minutes'] = df.apply(convert_to_minutes, axis=1)\n",
    "print(df['Duration_in_minutes'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9070741a0dec14f7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Почему я использовала именно такие способы заполнения пропусков?\n",
    "При работе с пропусками стратегия заполнения этих пропусков зависит от типа данных в столбце.\n",
    "- __Числовые столбцы__: Для числовых столбцов я использую медиану для заполнения пропусков. Причина этого в том, что медиана менее чувствительна к выбросам или искаженным данным по сравнению со средним значением. Если у меня есть набор данных с несколькими чрезвычайно высокими или низкими значениями, это может существенно повлиять на среднее значение, но не так сильно на медиану. Поэтому заполнение пропущенных значений медианой часто может привести к более правильному вычислению.\n",
    "- __Категориальные столбцы__: Для категориальных столбцов я использую моду для заполнения пропусков. Дело в том, что в таких столбцах нет “среднего” значения, как в числовых. Использование этого способа является простой и часто эффективной стратегией для заполнения пропусков в категориальных признаках, поскольку он представляет собой наиболее распространенный признак."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8970b58d5b8aada"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# EDA. 5. Are there outliers in the data?\n",
    "# We'll use the IQR method to detect outliers\n",
    "\n",
    "def detect_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "\n",
    "# Detect outliers in numeric columns\n",
    "numeric_columns.append('Duration_in_minutes')\n",
    "outliers = {}\n",
    "for column in numeric_columns:\n",
    "    outliers[column] = detect_outliers(df, column)\n",
    "    print(f'Outliers in {column}:\\n', outliers[column])\n",
    "\n",
    "# Removing outliers\n",
    "for column in numeric_columns:\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[~((df[column] < lower_bound) | (df[column] > upper_bound))]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ce988eb3012290a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# С помощью каких критериев я определяю выбросы?\n",
    "\n",
    "Я использую метод межквартильного разбиения (IQR). Это обычный статистический метод выявления отклонений с помощью вычисления IQR. IQR - это диапазон между первым и третьим квартилем данных (про квартили я объясняю ниже). Другими словами, IQR - это диапазон средних 50% данных.\n",
    "> Первый квартиль (25%) - это значение, <u>ниже</u> которого находится <u>25%</u> отсортированных по данному признаку данных. Грубо говоря, значение, стоящее на границе между первой и второй четвертью отсортированных данных. К примеру, первый квартиль рейтинга студентов ВШЭ - 75 процентиль, потому что ниже данной отметки находится четверть всех студентов.\n",
    "> Третий квартиль (75%) - это значение, <u>ниже</u> которого находится <u>75%</u> отсортированных по данному признаку данных. Возвращаясь к примеру с рейтингом студентов ВШЭ, это будет уже 25 процентиль, потому что ниже этой отметки находится 75% студентов.\n",
    "\n",
    "Теперь о том, как я использую метод IQR для выявления отклонений от нормы.\n",
    "1. Определяю нижнюю (lower_bound) и верхнюю (upper_bound) границу. Для вычисления нижней - вычитаю из первого квартиля (Q1) 1.5 * IQR, для вычисления верхней - к третьему квартилю (Q3) я прибавляю 1.5 * IQR.\n",
    "2. Беру все значения, которые меньше нижней границы __или__ больше верхней. Это и будут наши выбросы. Для логического \"или\" я использую унарный оператор \"|\"."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8520f3d83347a76f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# EDA. 6. Calculate descriptive statistics for variables\n",
    "descriptive_stats = df.describe()\n",
    "print(\"Descriptive statistics:\\n\", descriptive_stats)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65d0a8ec1e3df5f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# EDA. 7. Interpret descriptive statistics for one numeric attribute and for one categorical one.\n",
    "# Numeric attribute: Score\n",
    "print(\"Descriptive statistics for 'Score':\\n\", descriptive_stats['Score'])\n",
    "\n",
    "# Categorical attribute: Type\n",
    "type_counts = df['Type'].value_counts()\n",
    "print(\"Descriptive statistics for 'Type':\\n\", type_counts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6b7d7d8c0b0275e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualization. Визуализация. Постройте не менее трех графиков (причем, нужно использовать как минимум два типа визуализаций)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "365543690d66e4ff"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Visualization. 1. Boxplot of Scores\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(df['Score'], vert=False, patch_artist=True, medianprops={'linewidth': 3})\n",
    "plt.title('Boxplot of Scores')\n",
    "plt.xlabel('Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9c63e4abe0ac7e5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Вывод по визуализации 1\n",
    "."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5030d2276feb9603"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Visualization. 2. Bar plot of Type counts\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=df, x='Type')\n",
    "plt.title('Count of Anime Types')\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de76ec94b80de6e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Вывод по визуализации 2\n",
    "."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6693831df0ff5a3f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Visualization. 3. Scatter plot of Score vs Popularity\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Add a regression line\n",
    "sns.regplot(data=df, x='Score', y='Popularity', scatter_kws={'alpha':0.5})\n",
    "plt.title('Score vs Popularity')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Popularity')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e66eb35fab498b8a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Вывод по визуализации 3\n",
    "."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "357168795a71201c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 8. Build a correlation matrix for quantitative variables\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "print(\"Correlation matrix:\\n\", correlation_matrix)\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69aaee6a42c54b32"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 9. Implement 3 of the proposed 5 hypotheses\n",
    "\n",
    "# 9.1 Perform a z-test for mathematical expectation\n",
    "# Hypothesis: The average score of an anime is 7.5\n",
    "mean_score = df['Score'].mean()\n",
    "std_score = df['Score'].std()\n",
    "n = len(df['Score'])\n",
    "z_score = (mean_score - 7.5) / (std_score / np.sqrt(n))\n",
    "p_value = stats.norm.sf(abs(z_score)) * 2  # two-tailed test\n",
    "print(f'Hypothesis: The average score of an anime is 7.5\\n'\n",
    "      f'    Z-test: z_score = {z_score}, p_value = {p_value}')\n",
    "\n",
    "# 9.2 Take a t-test for mathematical expectation\n",
    "# Hypothesis: The average popularity of an anime is different from 5000\n",
    "t_stat, p_value = stats.ttest_1samp(df['Popularity'], 5000)\n",
    "print(f'Hypothesis: The average popularity of an anime is different from 5000\\n'\n",
    "      f'    T-test: t_stat = {t_stat}, p_value = {p_value}')\n",
    "\n",
    "# 9.3 Perform a test for the equality of mathematical expectations of two samples\n",
    "# Hypothesis: The average score of TV series is different from movies\n",
    "tv_scores = df[df['Type'] == 'TV']['Score']\n",
    "movie_scores = df[df['Type'] == 'Movie']['Score']\n",
    "t_stat, p_value = stats.ttest_ind(tv_scores, movie_scores)\n",
    "print(f'Hypothesis: The average score of TV series is different from movies\\n'\n",
    "      f'    Test for equality of means: t_stat = {t_stat}, p_value = {p_value}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "852a0336448383ec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 10. Build a linear or logistic regression of at least 3 features\n",
    "# Predicting Score based on Popularity, Members, and Duration_in_minutes\n",
    "X = df[['Popularity', 'Members', 'Duration_in_minutes']]\n",
    "y = df['Score']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 11. Evaluate the quality of the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Mean Absolute Error: {mae}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15cd29c55be50a6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
